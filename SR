误报率降到万分之五以下，漏报率控制在20%左右 

多人说话是声纹识别和语音识别都面临的问题，当前的所有模型都无法盲分离两个以上的人声并且同时进行识别

深度学习是基于数据驱动的模型，需要庞大的数据，这些数据最好是真实场景的数据，以及对数据的精确标注

声纹识别训练库的建立，至少要保证性别比例分布为50%±5%，包含有不同年龄段、不同地域、不同口音、不同职业

测试样本应该涵盖文本内容是否相关、采集设备、传输信道、环境噪音、录音回放、声音模仿、时间跨度、采样时长、健康状况和情感因素等影响声纹识别性能的主要因素

声纹识别对数据的要求其实比语音识别还要高很多
文本无关的识别系统在某些领域也会有重要的作用，例如刑侦比对




而SI可以间接分解为多个SV的问题，因此对于声纹识别系统性能的评测多是以SV的方式进行





语音具备了一个良好的性质，称为短时平稳，在一个20-50毫秒的范围内，语音近似可以看作是良好的周期信号。

音色是最能反映一个人身份信息的属性
音色差异表示频域不同频段能量的差异，通过抽取不同频段上的能量值，表示某个短时语音范围内频谱的性质

一段20-50毫秒长度的语音(以8KHz采样为例，这个长度的语音对应着160-400个采样点)可以映射为一段39-60维的向量

为了充分保留语音中的原始信息且不增加计算负担，通常以15-20毫秒为间隔依次取短时段语音，提取特征

梅尔倒谱系数MFCC、感知线性预测系数PLP  深度特征Deep Feature  能量规整谱系数PNCC

一段语音被映射为时间轴上一系列的向量集合

针对目标用户可采集到的语料是极其有限的(按照学术上的定义，实际可用的语音是稀疏(sparse)的)
